{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Part 1 - Regularization Techniques\n",
    "\n",
    "## Objective\n",
    "\n",
    "This lab applies four major regularization techniques to the deep models built in Lab 3 to combat overfitting:\n",
    "\n",
    "- **ℓ₁ and ℓ₂ Regularization:** Adding a penalty to the loss function based on the size of the weights.\n",
    "- **Dropout:** Randomly \"killing\" neurons during training to ensure the network doesn't over-rely on specific paths.\n",
    "- **Max-Norm Regularization:** Constraining the weights of each neuron so they don't grow too large.\n",
    "\n",
    "## Conceptual Background\n",
    "\n",
    "| Technique | Description | Effect |\n",
    "|-----------|-------------|--------|\n",
    "| **ℓ₁ Regularization** | Adds penalty proportional to absolute weight values | Produces sparse models (weights become exactly zero), effectively acting as feature selection |\n",
    "| **ℓ₂ Regularization** | Adds penalty proportional to squared weight values | Keeps weights small but rarely zero, helps handle multicollinearity |\n",
    "| **Dropout** | Randomly deactivates neurons during training | Forces the network to learn redundant representations, making it more robust |\n",
    "| **Max-Norm** | Rescales weight vector w such that \\|\\|w\\|\\|₂ ≤ c | Prevents weights from growing too large, where c is the max-norm hyperparameter |"
   ],
   "id": "163f4f0cbea259ec"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Step 1: $\\ell_1$ and $\\ell_2$\n",
    "## RegularizationWe will apply these to a Dense network similar to your MNIST/CIFAR-10 tasks."
   ],
   "id": "278c1327f80b7b74"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T07:47:16.208220789Z",
     "start_time": "2026-02-19T07:47:11.699059340Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# 1. Define l2 regularization factor\n",
    "# This adds a penalty to the loss: Loss + 0.01 * sum(weights^2)\n",
    "regularizer = keras.regularizers.l2(0.01)\n",
    "\n",
    "model_l2 = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[32, 32, 3]), # Using CIFAR-10 shape as example\n",
    "    keras.layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\",\n",
    "                       kernel_regularizer=regularizer),\n",
    "    keras.layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\",\n",
    "                       kernel_regularizer=regularizer),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "# If you want to use l1, simply use: keras.regularizers.l1(0.01)\n",
    "# For both (Elastic Net style): keras.regularizers.l1_l2(0.01, 0.01)\n",
    "\n",
    "model_l2.compile(loss=\"categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])"
   ],
   "id": "3209cb1c10e1ece6",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-19 08:47:12.089219: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/clauds/anaconda3/envs/tf_env/lib/python3.12/site-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
