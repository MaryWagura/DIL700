{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-25T14:13:17.735747688Z",
     "start_time": "2026-01-25T14:13:15.180522573Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys\n",
    "print(\"Python path:\", sys.executable)\n",
    "print(\"Python version:\", sys.version)\n",
    "\n",
    "# Try to import\n",
    "try:\n",
    "    import numpy as np\n",
    "    print(\"NumPy version:\", np.__version__)\n",
    "except ImportError:\n",
    "    print(\"NumPy NOT found\")\n",
    "\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "    print(\"TensorFlow version:\", tf.__version__)\n",
    "except ImportError:\n",
    "    print(\"TensorFlow NOT found\")"
   ],
   "id": "1e3bc7ca6fc5502b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python path: /home/clauds/anaconda3/envs/tf_env/bin/python\n",
      "Python version: 3.12.12 | packaged by Anaconda, Inc. | (main, Oct 21 2025, 20:16:04) [GCC 11.2.0]\n",
      "NumPy version: 2.1.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-25 15:13:15.428626: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.20.0\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# PART 1",
   "id": "a05c1c94915c1c64"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Task 1: Create Two Sample Tensors\n",
    "\n",
    "We will create high-dimensional arrays (tensors). Deep learning models often work with 3D or 4D tensors. For example, a batch of color images is 4D:\n",
    "\n",
    "**Batch Size × Height × Width × Color Channels**\n",
    "\n",
    "### Explanation:\n",
    "\n",
    "We will use `np.random.randint` to generate random integers. This is often better for learning than `np.zeros` or `np.ones` because it makes it easier to track how data moves during reshaping or slicing."
   ],
   "id": "36bc37a294703e97"
  },
  {
   "cell_type": "code",
   "id": "29ff8640-3999-451c-a654-116c23c3724a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-25T14:14:02.899679841Z",
     "start_time": "2026-01-25T14:14:02.617979663Z"
    }
   },
   "source": [
    "# Create two 3-D tensors of shape (2, 3, 4)\n",
    "# Think of this as: 2 matrices, each having 3 rows and 4 columns\n",
    "tensor_a = np.random.randint(low=0, high=10, size=(2, 3, 4))\n",
    "tensor_b = np.random.randint(low=0, high=10, size=(2, 3, 4))\n",
    "\n",
    "print(\"Tensor A:\\n\", tensor_a)\n",
    "print(\"\\nShape of Tensor A:\", tensor_a.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor A:\n",
      " [[[5 2 9 6]\n",
      "  [4 6 5 9]\n",
      "  [1 2 2 5]]\n",
      "\n",
      " [[6 9 6 9]\n",
      "  [5 3 8 5]\n",
      "  [4 0 9 4]]]\n",
      "\n",
      "Shape of Tensor A: (2, 3, 4)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Task 2: Element-wise Addition\n",
    "\n",
    "### Explanation:\n",
    "\n",
    "Element-wise operations apply a mathematical operation between corresponding elements in two tensors. For this to work without \"broadcasting\" (an advanced topic), the two tensors usually need to have the exact same shape.\n",
    "\n",
    "Mathematically, if $C = A + B$, then for every specific position $(i, j, k)$:\n",
    "\n",
    "$$C_{ijk} = A_{ijk} + B_{ijk}$$"
   ],
   "id": "1882749950511dc4"
  },
  {
   "cell_type": "code",
   "id": "07c859cb-9b8c-425c-b528-6159484bcc63",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-25T14:14:11.013412843Z",
     "start_time": "2026-01-25T14:14:10.576387199Z"
    }
   },
   "source": [
    "# Adding two tensors of the exact same shape\n",
    "tensor_sum = tensor_a + tensor_b\n",
    "\n",
    "print(\"Sum:\\n\", tensor_sum)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum:\n",
      " [[[ 5 11 15 15]\n",
      "  [ 5  6  8 11]\n",
      "  [ 1  9  9  9]]\n",
      "\n",
      " [[ 7 12 10 16]\n",
      "  [ 6  3 13 13]\n",
      "  [ 8  6 18 10]]]\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Task 3: Element-wise Multiplication\n",
    "\n",
    "### Explanation:\n",
    "\n",
    "This is often called the **Hadamard Product**. It is **not** the same as Matrix Multiplication (Dot Product).\n",
    "\n",
    "In element-wise multiplication, we simply multiply the number at position `[0,0,0]` in Tensor A by the number at `[0,0,0]` in Tensor B.\n",
    "\n",
    "**Symbol:** Often denoted by $\\odot$ or simply `*` in code.\n",
    "\n",
    "**Use case:** Used frequently in neural networks for operations like:\n",
    "- Masking (hiding certain parts of an image)\n",
    "- Activation functions\n",
    "- Attention mechanisms"
   ],
   "id": "49a35a88ce00fa16"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "109b785a-728e-4671-95bf-bd53e4e429d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Element-wise Product:\n",
      " [[[ 0  4 21 40]\n",
      "  [63 54  9  0]\n",
      "  [12  3 27 24]]\n",
      "\n",
      " [[ 0 16 48  9]\n",
      "  [ 0  3 28 35]\n",
      "  [24 15 30  0]]]\n"
     ]
    }
   ],
   "source": [
    "# Element-wise multiplication\n",
    "tensor_mult = tensor_a * tensor_b\n",
    "\n",
    "print(\"Element-wise Product:\\n\", tensor_mult)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Task 4: Reshape a Tensor\n",
    "\n",
    "### Explanation:\n",
    "\n",
    "Reshaping is critical in Deep Learning. You might need to flatten an image (2D) into a vector (1D) to feed it into a standard neural network layer.\n",
    "\n",
    "#### The Golden Rule of Reshaping:\n",
    "**The total number of elements must remain the same.**\n",
    "\n",
    "Our `tensor_a` has shape $(2, 3, 4)$.\n",
    "\n",
    "**Total elements:** $2 \\times 3 \\times 4 = 24$\n",
    "\n",
    "We can reshape this into any shape that multiplies to 24, such as:\n",
    "- $(6, 4)$\n",
    "- $(24,)$\n",
    "- $(1, 24)$\n",
    "- $(2, 2, 6)$\n",
    "- $(4, 3, 2)$"
   ],
   "id": "654fcd9adfea82f3"
  },
  {
   "cell_type": "code",
   "id": "c88a2bd7-cb3f-4c6c-b341-d43b19f7f0ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-25T14:14:46.164760343Z",
     "start_time": "2026-01-25T14:14:46.018713717Z"
    }
   },
   "source": [
    "# Reshaping the (2, 3, 4) tensor into a 2D matrix of shape (6, 4)\n",
    "reshaped_tensor = tensor_a.reshape(6, 4)\n",
    "\n",
    "print(\"Original Shape:\", tensor_a.shape)\n",
    "print(\"New Shape:\", reshaped_tensor.shape)\n",
    "print(\"\\nReshaped Tensor:\\n\", reshaped_tensor)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Shape: (2, 3, 4)\n",
      "New Shape: (6, 4)\n",
      "\n",
      "Reshaped Tensor:\n",
      " [[5 2 9 6]\n",
      " [4 6 5 9]\n",
      " [1 2 2 5]\n",
      " [6 9 6 9]\n",
      " [5 3 8 5]\n",
      " [4 0 9 4]]\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Task 5: Slicing and Indexing\n",
    "\n",
    "### Explanation:\n",
    "\n",
    "Slicing allows you to extract specific sub-sections of your tensor. The syntax follows `[start:stop:step]`.\n",
    "\n",
    "#### Key Syntax Rules:\n",
    "- `:` selects everything in that dimension\n",
    "- `0:2` selects indices 0 up to (but not including) 2\n",
    "- You can omit values: `:` is same as `0:`, `:3` selects first 3 elements\n",
    "\n",
    "#### 3D Tensor Structure:\n",
    "Since our tensor is 3D with dimensions **(Block, Row, Column)**, we need:\n",
    "- Three indices to access a specific element (e.g., `tensor[0, 1, 2]`)\n",
    "- Ranges to access chunks (e.g., `tensor[0, 0:2, :]`)\n",
    "\n",
    "#### Examples:\n",
    "```python\n",
    "# Get first block, first 2 rows, all columns\n",
    "slice_example = tensor_a[0, 0:2, :]\n",
    "\n",
    "# Get all blocks, all rows, first 3 columns\n",
    "slice_example = tensor_a[:, :, 0:3]\n",
    "\n",
    "# Get every other block\n",
    "slice_example = tensor_a[::2, :, :]"
   ],
   "id": "a445e1bdf86f2657"
  },
  {
   "cell_type": "code",
   "id": "d1a7996a-8380-4cbf-a5eb-9c117c3908e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-25T14:14:54.544460258Z",
     "start_time": "2026-01-25T14:14:54.365555854Z"
    }
   },
   "source": [
    "# Select the first block, first 2 rows, and all columns\n",
    "# Syntax: tensor[dimension_1, dimension_2, dimension_3]\n",
    "slice_example = tensor_a[0, 0:2, :]\n",
    "\n",
    "print(\"Original Shape:\", tensor_a.shape)\n",
    "print(\"Sliced Shape:\", slice_example.shape)\n",
    "print(\"\\nSliced Data:\\n\", slice_example)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Shape: (2, 3, 4)\n",
      "Sliced Shape: (2, 4)\n",
      "\n",
      "Sliced Data:\n",
      " [[5 2 9 6]\n",
      " [4 6 5 9]]\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-25T14:14:57.690517563Z",
     "start_time": "2026-01-25T14:14:57.498831172Z"
    }
   },
   "cell_type": "markdown",
   "source": [
    "## Task 6: Combining Tensors\n",
    "\n",
    "### Explanation:\n",
    "\n",
    "In Neural Networks, you often need to merge data. For example:\n",
    "- Merging two different features of a dataset\n",
    "- Combining outputs from multiple network branches\n",
    "- Batch processing of multiple samples\n",
    "\n",
    "### Two Main Methods:\n",
    "\n",
    "#### 1. Concatenation\n",
    "Joins tensors **along an existing axis**. The dimension of that axis increases.\n",
    "\n",
    "Example: Concatenating two `(2, 3, 4)` tensors along axis=0 gives `(4, 3, 4)`\n",
    "\n",
    "#### 2. Stacking\n",
    "Joins tensors **along a new axis**. The rank (number of dimensions) increases.\n",
    "\n",
    "Example: Stacking two `(2, 3, 4)` tensors gives `(2, 2, 3, 4)` (new axis at position 0)\n",
    "\n",
    "### In This Task:\n",
    "We will use `np.concatenate`. If we concatenate along `axis=0`, we are adding more \"blocks\" to our pile.\n",
    "\n",
    "#### Syntax:\n",
    "```python\n",
    "# Concatenate along axis 0 (stack vertically)\n",
    "combined = np.concatenate((tensor_a, tensor_b), axis=0)\n",
    "\n",
    "# Result: (2,3,4) + (2,3,4) → (4,3,4)"
   ],
   "id": "f2d06ba54a7d502b"
  },
  {
   "cell_type": "code",
   "id": "0f4b9c51-0dcd-4db5-b3d5-e0ae4a788998",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-25T14:16:23.119048422Z",
     "start_time": "2026-01-25T14:16:23.045775529Z"
    }
   },
   "source": [
    "# Concatenating along axis 0 (stacking them on top of each other vertically)\n",
    "# (2,3,4) + (2,3,4) -> (4,3,4)\n",
    "combined_tensor = np.concatenate((tensor_a, tensor_b), axis=0)\n",
    "\n",
    "print(\"Shape after concatenation:\", combined_tensor.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after concatenation: (4, 3, 4)\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Task 7: Splitting Tensors\n",
    "\n",
    "### Explanation:\n",
    "\n",
    "This is the inverse of concatenation. You might use this to:\n",
    "- Split a dataset into \"Training\" and \"Testing\" sets\n",
    "- Divide batches for parallel processing\n",
    "- Separate features for different processing paths\n",
    "\n",
    "`np.array_split` allows us to divide the tensor into equal (or near-equal) chunks.\n",
    "\n",
    "#### Key Function:\n",
    "```python\n",
    "np.array_split(array, indices_or_sections, axis=0)"
   ],
   "id": "dd27ea8d167fa28a"
  },
  {
   "cell_type": "code",
   "id": "ccdfa79a-1198-4bd6-9472-420f411b4c94",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-25T14:16:25.560945035Z",
     "start_time": "2026-01-25T14:16:25.468009044Z"
    }
   },
   "source": [
    "# Split the large combined tensor into 2 equal parts\n",
    "# We combined them earlier, now we split them back\n",
    "split_tensors = np.array_split(combined_tensor, 2, axis=0)\n",
    "\n",
    "print(\"Shape of first split:\", split_tensors[0].shape)\n",
    "print(\"Shape of second split:\", split_tensors[1].shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of first split: (2, 3, 4)\n",
      "Shape of second split: (2, 3, 4)\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Task 8: Basic Mathematical Operations\n",
    "\n",
    "### Explanation:\n",
    "\n",
    "These are **\"Aggregation\" functions**. They take a tensor and reduce it to a smaller shape (or a single number) by summarizing the data.\n",
    "\n",
    "#### Common Aggregation Functions:\n",
    "\n",
    "##### 1. `sum()`\n",
    "Adds everything up.\n",
    "```python\n",
    "total = np.sum(tensor)  # Global sum\n",
    "\n",
    "##### 2. `mean()`\n",
    "Adds everything up.\n",
    "```python\n",
    "average = np.mean(tensor)  # Global mean\n",
    "\n",
    "\n",
    "##### 1. `std()`\n",
    "Adds everything up.\n",
    "```python\n",
    "total = np.std(tensor)  # Global std"
   ],
   "id": "95309f2d329c3da1"
  },
  {
   "cell_type": "code",
   "id": "d40d9fc9-5ec8-48a1-b0c0-b9adc49fd6d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-25T14:16:34.428832163Z",
     "start_time": "2026-01-25T14:16:34.282376748Z"
    }
   },
   "source": [
    "# Global aggregation (reduces to a single number)\n",
    "total_sum = np.sum(tensor_a)\n",
    "mean_val = np.mean(tensor_a)\n",
    "\n",
    "# Aggregation along an axis (reduces dimensions)\n",
    "# Summing along axis 0 collapses the two \"blocks\" together\n",
    "sum_axis_0 = np.sum(tensor_a, axis=0)\n",
    "\n",
    "print(f\"Total Sum: {total_sum}\")\n",
    "print(f\"Mean Value: {mean_val}\")\n",
    "print(f\"Sum along Axis 0 shape: {sum_axis_0.shape}\") # Should be (3, 4)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sum: 124\n",
      "Mean Value: 5.166666666666667\n",
      "Sum along Axis 0 shape: (3, 4)\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# TASK 2",
   "id": "adad11706fb86c09"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## We will use Keras, which is the high-level API built into TensorFlow. Keras makes deep learning accessible by abstracting away the complex mathematics of tensor calculus, allowing you to focus on the architecture.",
   "id": "d2dd1449736a22a9"
  },
  {
   "cell_type": "code",
   "id": "50740c6f-e8be-4d66-8982-f2c2f1a2cb35",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-25T14:16:43.545919891Z",
     "start_time": "2026-01-25T14:16:43.504770947Z"
    }
   },
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Step 1: Define a Simple Neural Network Model\n",
    "\n",
    "\n",
    "### Key Components Explained:\n",
    "\n",
    "#### 1. `Sequential()`\n",
    "Creates a linear stack of layers. Data flows sequentially from input to output through each layer in order.\n",
    "\n",
    "#### 2. `Dense`\n",
    "A **fully connected layer**. Every neuron in this layer is connected to every neuron in the previous layer.\n",
    "\n",
    "#### 3. `Units`\n",
    "The number of **neurons (nodes)** in that layer.\n",
    "- **More units** = More capacity to learn complex patterns\n",
    "- **More units** = Higher computational cost and risk of overfitting\n",
    "- Typical range: 16-512 neurons per layer\n",
    "\n",
    "#### 4. `ReLU` (Rectified Linear Unit)\n",
    "The standard activation function for hidden layers:\n",
    "$$f(x) = \\max(0, x)$$\n",
    "\n",
    "**Benefits:**\n",
    "- Computationally efficient (simple max operation)\n",
    "- Helps prevent the **\"vanishing gradient\"** problem\n",
    "- Introduces non-linearity while keeping gradients large for positive inputs\n",
    "\n",
    "#### 5. `Sigmoid`\n",
    "Used for binary classification output:\n",
    "$$f(x) = \\frac{1}{1 + e^{-x}}$$\n",
    "\n",
    "**Characteristics:**\n",
    "- Forces the output to be a probability between **0 and 1**\n",
    "- Interpretable as confidence scores\n",
    "- Used in the final layer for binary classification tasks\n",
    "\n",
    "---\n",
    "\n",
    "#### Practical Example:\n",
    "```python\n",
    "model = models.Sequential([\n",
    "    # Input layer: 8 features → 16 neurons with ReLU\n",
    "    layers.Dense(units=16, activation='relu', input_shape=(8,)),\n",
    "\n",
    "    # Hidden layer: 16 neurons → 8 neurons with ReLU\n",
    "    layers.Dense(units=8, activation='relu'),\n",
    "\n",
    "    # Output layer: 8 neurons → 1 neuron with Sigmoid (binary output)\n",
    "    layers.Dense(units=1, activation='sigmoid')\n",
    "])\n"
   ],
   "id": "c130c1f6bea872e7"
  },
  {
   "cell_type": "code",
   "id": "0e8d798b-5e64-492b-be4f-b1c1ff416052",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-25T14:16:54.856636180Z",
     "start_time": "2026-01-25T14:16:54.676962727Z"
    }
   },
   "source": [
    "# Initialize the container (the empty stack)\n",
    "model = models.Sequential()\n",
    "\n",
    "# 1. Add the first hidden layer\n",
    "# - units=16: This layer has 16 neurons (\"thinking units\").\n",
    "# - activation='relu': Rectified Linear Unit. It turns negative values to 0. \n",
    "# - input_shape=(8,): We expect an input vector with 8 features.\n",
    "model.add(layers.Dense(units=16, activation='relu', input_shape=(8,)))\n",
    "\n",
    "# 2. Add a second hidden layer\n",
    "# We don't need input_shape here; Keras infers it from the previous layer.\n",
    "model.add(layers.Dense(units=8, activation='relu'))\n",
    "\n",
    "# 3. Add the output layer\n",
    "# - units=1: A single number output (e.g., probability of \"True\")\n",
    "# - activation='sigmoid': Squashes the output between 0 and 1.\n",
    "model.add(layers.Dense(units=1, activation='sigmoid'))"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/clauds/anaconda3/envs/tf_env/lib/python3.12/site-packages/keras/src/layers/core/dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Step 2: Compile the Model\n",
    "\n",
    "### In-Depth Explanation:\n",
    "\n",
    "Defining the architecture (Step 1) is like building a car. Compiling is like connecting the engine, filling the gas tank, and installing the GPS. You are configuring how the model will learn.\n",
    "\n",
    "You must specify three things:\n",
    "\n",
    "### Optimizer: The mechanic.\n",
    "It updates the weights based on the data to reduce error. Adam is the industry standard (it's adaptive and fast).\n",
    "\n",
    "### Loss Function: The GPS.\n",
    "It calculates how far off the model's predictions are from the actual answers.\n",
    "\n",
    "- Use binary_crossentropy for Yes/No tasks.\n",
    "- Use categorical_crossentropy for Multi-class tasks.\n",
    "- Use mean_squared_error for Regression (predicting prices, temp).\n",
    "\n",
    "### Metrics: The dashboard.\n",
    "These are numbers for us (humans) to read, like \"Accuracy\". The model doesn't use this for learning, just for reporting."
   ],
   "id": "5f0de29175336d32"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "**Optimizer ('adam'):** A gradient descent algorithm that adjusts the learning rate automatically. It is generally the best \"default\" choice.\n",
    "\n",
    "**Loss ('binary_crossentropy'):** The math formula that quantifies \"error\" for binary classification tasks. The goal of training is to minimize this number.\n",
    "\n",
    "**Metrics ('accuracy'):** The percentage of correct predictions. Easier for humans to understand than the raw loss value."
   ],
   "id": "e308e7685a751e02"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "467ab658-aea7-4a1a-8de4-5c640f695e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Step 3: Print Model Summary\n",
    "\n",
    "### In-Depth Explanation:\n",
    "\n",
    "The `summary()` method is a crucial debugging tool. It prints a table showing the structure of your network.\n",
    "\n",
    "**Key things to look for:**\n",
    "\n",
    "**Output Shape:** It will look like `(None, 16)`. The `None` represents the Batch Size. The model doesn't care if you feed it 1 example or 100 examples at once; it's flexible. The `16` is the number of neurons in that layer.\n",
    "\n",
    "**Param # (Parameters):** This is the total number of \"knobs\" the model can turn to learn patterns.\n",
    "\n",
    "**Calculation:** For a Dense layer, parameters = $(Inputs \\times Neurons) + Bias$.\n",
    "\n",
    "**Example for our first layer:** 8 inputs $\\times$ 16 neurons + 16 biases = $128 + 16 = 144$ parameters."
   ],
   "id": "5ffe5c7fdd19dae1"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dcb47a04-b173-47b2-8876-26349a6cd531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001B[1mModel: \"sequential_1\"\u001B[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">136</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                        \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape               \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m        Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_3 (\u001B[38;5;33mDense\u001B[0m)                      │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m16\u001B[0m)                  │             \u001B[38;5;34m144\u001B[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_4 (\u001B[38;5;33mDense\u001B[0m)                      │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m8\u001B[0m)                   │             \u001B[38;5;34m136\u001B[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_5 (\u001B[38;5;33mDense\u001B[0m)                      │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m)                   │               \u001B[38;5;34m9\u001B[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">289</span> (1.13 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m289\u001B[0m (1.13 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">289</span> (1.13 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m289\u001B[0m (1.13 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# View the architecture and parameter count\n",
    "model.summary()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# PART 3- Classification Tasks: Build and train a fully connected neural network for classification tasks using first MNIST and then IMDb datasets by repeating the eight steps below:",
   "id": "288290b83c669946"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Part A: MNIST (Image Classification)\n",
    "\n",
    "**Objective**: Classify 28x28 pixel grayscale images of handwritten digits (0-9) into their respective categories.\n",
    "\n",
    "## Step 1: Load and Preprocess the Dataset\n",
    "\n",
    "**Explanation**:\n",
    "- **Loading**: We use Keras to load the MNIST dataset, which contains 60,000 training images and 10,000 test images.\n",
    "- **Normalization**: Pixel values range from 0 to 255. We divide by 255.0 to scale them into the range [0, 1]. This helps the neural network converge faster and prevents \"exploding gradients.\""
   ],
   "id": "48d0634ca601f4a8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = datasets.mnist.load_data()\n",
    "\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
    "\n",
    "print(f\"Training Data Shape: {train_images.shape}\")\n",
    "print(f\"Test Data Shape: {test_images.shape}\")"
   ],
   "id": "7768a2ce52042c79"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Step 2: Define the Neural Network Model\n",
    "\n",
    "**Explanation**:\n",
    "- **Flatten**: Transforms the 2D image (28×28) into a 1D array (784 pixels). This is necessary because standard Dense layers expect flat vectors.\n",
    "- **Dense (Hidden)**: A layer with 128 neurons and ReLU activation to learn non‑linear patterns.\n",
    "- **Dense (Output)**: A layer with 10 neurons (one for each digit). We use Softmax activation to output a probability distribution across the 10 classes (sum of outputs = 1)."
   ],
   "id": "8e3d960142d2ec68"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model_mnist = models.Sequential([\n",
    "    layers.Flatten(input_shape=(28, 28)),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])"
   ],
   "id": "746aaabba3ec884e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Step 3: Compile the Model\n",
    "\n",
    "**Explanation**:\n",
    "- **Optimizer (Adam)**: An adaptive learning rate optimization algorithm.\n",
    "- **Loss (Sparse Categorical Crossentropy)**: Used when classes are mutually exclusive (e.g., a digit cannot be both 1 and 2) and labels are integers.\n",
    "- **Metrics**: We track accuracy to interpret performance easily."
   ],
   "id": "779348137d939766"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model_mnist.compile(optimizer='adam',\n",
    "                    loss='sparse_categorical_crossentropy',\n",
    "                    metrics=['accuracy'])"
   ],
   "id": "e7d5bbd44bc80fbd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Step 4: Train the Model\n",
    "\n",
    "**Explanation**: We train for 5 epochs using 20% of the training data for validation. The history object captures the loss and accuracy metrics at the end of each epoch, which is vital for plotting later."
   ],
   "id": "1253f0d5c909efe9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "history_mnist = model_mnist.fit(train_images, train_labels,\n",
    "                                epochs=5,\n",
    "                                validation_split=0.2)"
   ],
   "id": "9902f6dc10a58488"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Step 5: Evaluate Model & Plot Performance Indicators\n",
    "\n",
    "**Explanation**: We utilize matplotlib to define a reusable function for plotting. This allows us to compare Training vs. Validation performance side-by-side."
   ],
   "id": "92f1cb863038623a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def plot_history(history, title_prefix=\"\"):\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    # Plot Accuracy\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "    plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "    plt.title(f'{title_prefix} Training and validation accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot Loss\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "    plt.title(f'{title_prefix} Training and validation loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()"
   ],
   "id": "c5f953b4b0c1b047"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Steps 6 & 7: Plot Loss and Accuracy over Epochs\n",
    "\n",
    "**Explanation**: We call our function to visualize the MNIST training.\n",
    "\n",
    "**Ideal result**: Accuracy increases, Loss decreases. Validation lines should track closely with Training lines."
   ],
   "id": "3903834b9a915f55"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "plot_history(history_mnist, title_prefix=\"MNIST\")",
   "id": "2bfb5aba46820610"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Step 8: Display Test Loss and Accuracy\n",
    "\n",
    "**Explanation**: Finally, we check how the model performs on the Test Set—data it has never seen before. This is the true measure of the model's ability to generalize."
   ],
   "id": "4b7d62843a672f6f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "test_loss, test_acc = model_mnist.evaluate(test_images, test_labels, verbose=2)\n",
    "print(f'\\nMNIST Test accuracy: {test_acc:.4f}')"
   ],
   "id": "ce45d5f9a4ce30cb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Part B: IMDb (Text Classification)\n",
    "\n",
    "**Objective**: Classify movie reviews as either Positive (1) or Negative (0) based on the text.\n",
    "\n",
    "## Step 1: Load and Preprocess the Dataset\n",
    "\n",
    "**Explanation**:\n",
    "- **Vocabulary**: We limit the dataset to the top 10,000 most frequently used words. Less common words are discarded to keep the model manageable.\n",
    "- **Padding**: Neural networks require inputs of the same shape. Since reviews have different lengths (word counts), we use pad_sequences to cut long reviews or add zeros to short ones, ensuring every input is exactly 256 words long."
   ],
   "id": "af063bd38f4a1203"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from tensorflow.keras.preprocessing import sequence\n",
    "\n",
    "# Load data, keeping only the top 10,000 most frequent words\n",
    "(train_data, train_labels), (test_data, test_labels) = datasets.imdb.load_data(num_words=10000)\n",
    "\n",
    "# Pad sequences so all reviews are length 256\n",
    "train_data = sequence.pad_sequences(train_data, maxlen=256)\n",
    "test_data = sequence.pad_sequences(test_data, maxlen=256)\n",
    "\n",
    "print(f\"IMDb Train Shape (padded): {train_data.shape}\")"
   ],
   "id": "e3f5e8b768188596"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Step 2: Define the Neural Network Model\n",
    "\n",
    "**Explanation**:\n",
    "- **Embedding Layer**: This is crucial for NLP. It converts integer indices (representing words) into dense vectors of fixed size (16). It learns semantic relationships between words during training.\n",
    "- **GlobalAveragePooling1D**: This averages the vector of the review to a single dimension, handling the variable length of features efficiently.\n",
    "- **Dense (16, relu)**: Standard hidden processing layer.\n",
    "- **Dense (1, sigmoid)**: Single output neuron with Sigmoid activation. It squashes the result between 0 and 1 (closer to 0 = Negative, closer to 1 = Positive)."
   ],
   "id": "ab1c217978c279db"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model_imdb = models.Sequential([\n",
    "    layers.Embedding(input_dim=10000, output_dim=16),\n",
    "    layers.GlobalAveragePooling1D(),\n",
    "    layers.Dense(16, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])"
   ],
   "id": "f9128c462fb012dd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Step 3: Compile the Model\n",
    "\n",
    "**Explanation**:\n",
    "- **Loss (Binary Crossentropy)**: The standard loss function for binary (Yes/No) classification tasks."
   ],
   "id": "fc64539d28f9ee5d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model_imdb.compile(optimizer='adam',\n",
    "                   loss='binary_crossentropy',\n",
    "                   metrics=['accuracy'])"
   ],
   "id": "98908a6c374d822d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Step 4: Train the Model\n",
    "\n",
    "**Explanation**: We train the model. Note that text models can overfit quickly (where training accuracy hits 100% but validation stalls), so we monitor the validation split closely."
   ],
   "id": "e9b2ee7286c672e0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "history_imdb = model_imdb.fit(train_data, train_labels,\n",
    "                              epochs=10,\n",
    "                              batch_size=512,\n",
    "                              validation_split=0.2)"
   ],
   "id": "f6ef76e6c566f2f3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Steps 5, 6 & 7: Evaluate and Plot Performance\n",
    "\n",
    "**Explanation**: We reuse the plotting function from Part A.\n",
    "\n",
    "**Observation**: You might notice the Validation Loss starts increasing after a few epochs while Training Loss keeps going down. This is overfitting."
   ],
   "id": "2651cb3325b61dc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "plot_history(history_imdb, title_prefix=\"IMDb\")",
   "id": "1b01f1c6c7b20c11"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Step 8: Display Test Loss and Accuracy\n",
    "\n",
    "**Explanation**: Evaluate the final performance on the movie review test set."
   ],
   "id": "447da9aa06131c45"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "results = model_imdb.evaluate(test_data, test_labels, verbose=2)\n",
    "print(f\"\\nIMDb Test Accuracy: {results[1]:.4f}\")"
   ],
   "id": "c664af2e3349e434"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
